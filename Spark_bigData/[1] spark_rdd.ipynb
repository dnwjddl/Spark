{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 세가지\n",
    "## RDD (비구조적) :schema Free <immutable>\n",
    "## DataFrame (구조적) : schema <immutable>\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver 내 SparkSession\n",
    "#SparkSession 내 SparkContext\n",
    "#SparkContext 내 RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(conf=myConf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD\n",
    "## RDD의 두가지 처리 방법\n",
    "- 변환(Transform) - lazy, action 없으면 안보여줌 \n",
    "- 행동(Action)\n",
    "\n",
    "## RDD 생성 방법\n",
    "- 내부: 이미 만들어진 배열과 같이 읽어서 생성 , Parallelize() 함수사용\n",
    "- 외부: 파일, 데이터 베이스등 외부에서 읽어와서 실행, TextFile() 함수사용\n",
    "\n",
    "## RDD API\n",
    "- Transformations- RDD로 반환<br>\n",
    "\n",
    "함수 | 설명 | 예제\n",
    "-------|-------|-------\n",
    "```map(fn)``` | 요소별로 fn을 적용해서 결과 RDD 돌려줌 | ```.map(lambda x: x.split(' ')```\n",
    "```filter(fn)``` | 요소별로 선별하여 fn을 적용해서 결과 RDD 돌려줌 | ```.filter(lambda x: \"Spark\" in x)```\n",
    "```flatMap(fn)``` | 요소별로 fn을 적용하고, flat해서 결과 RDD 돌려줌 | ```.flatMap(lambda x: x.split(' '))```\n",
    "```groupByKey()``` | key를 그룹해서 iterator를 돌려줌. |\n",
    "<br>\n",
    "\n",
    "- Action- list로 반환 <br> \n",
    "\n",
    "함수 | 설명 | 예제\n",
    "-------|-------|-------\n",
    "```reduce(fn)``` | 요소별로 fn을 사용해서 줄여서 결과 list를 돌려줌 | ```reduce(lambda x,y:x+y)```\n",
    "```collect()``` | 모든 요소를 결과 list로 돌려줌 |\n",
    "```count()``` | 요소의 갯수를 결과 list로 돌려줌 |\n",
    "```take(n)``` | ```collect()```는 전체이지만, n개만 돌려줌 | ```take(1)```\n",
    "```countByKey()``` | key별 갯수를 세는 함수 | ```countByKey().items()```\n",
    "```foreach(fn)``` | 각 데이터 항목에 함수fn을 적용 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 내부 생성방법\n",
    "myList = [1,2,3,4,5] #type = <class 'list'>\n",
    "myRdd1 = spark.sparkContext.parallelize(myList) #type = <class 'pyspark.rdd.RDD'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 외부 생성방법\n",
    "import os\n",
    "myRdd2 = spark.sparkContext\\\n",
    "            .textFile(os.path.join(\"s-master/data\",\"ds_spark_wiki.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Action\n",
    "print(myRdd1.take(3))\n",
    "print(myRdd2.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map() : map함수 사용하면 for 문 없이도 처리 가능\n",
    "#### filter(): 데이터 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102.56, 97.7, 99.14, 100.03999999999999]\n"
     ]
    }
   ],
   "source": [
    "#python에서 map 함수\n",
    "celsius = [39.2, 36.5, 37.3, 37.8]\n",
    "def c2f(c):\n",
    "    return(float(9)/5)*c +32\n",
    "f = map(c2f, celsius) # <class 'map'>\n",
    "print(list(f)) #list로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_map = map(lambda c: (float(9)/5)*c +32, celsius)\n",
    "f_list = list(map(lambda c: (float(9)/5)*c +32, celsius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['H'], ['e'], ['l'], ['l'], ['o'], [], ['W'], ['o'], ['r'], ['l'], ['d']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Hello World\" #class 'str'\n",
    "sent=list(map(lambda x: x.split(), sentence))\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'World'], ['Good', 'Morining']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"Hello World\", \"Good Morining\"] #class 'list'\n",
    "list_sent=list(map(lambda x:x.split(), sentence))\n",
    "list_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 5, 13, 21, 55]\n"
     ]
    }
   ],
   "source": [
    "#filter()\n",
    "fib=[0,1,1,2,3,5,8,13,21,34,55]\n",
    "result = filter(lambda x: x%2, fib) #홀수만 출력한것임\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce()\n",
    "- reduce() 역시 함수와 데이터 2개의 인자를 받음.\n",
    "- 데이터에 대해 함수를 반복적으로 적용하여 결과 값을 만들게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "reduce(lambda x, y: x + y, range(1,101))\n",
    "#1부터 100까지 더한 결과가 나오게 됨 \n",
    "#x를 부분합계, y을 1부터 증가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "** \n",
    "y = list()\n",
    "for i in x:\n",
    "    y.append(int(i))\n",
    "    \n",
    "** \n",
    "y = [int(i) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark 에서 RDD 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[20] at RDD at PythonRDD.scala:53\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "nRdd = spark.sparkContext.parallelize([1, 2, 3, 4])\n",
    "squared = nRdd.map(lambda x: x*x)\n",
    "#데이터.map(function)\n",
    "print(squared)\n",
    "print(type(squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Map() 은 transformation 함수라서, 실제 값은 action 함수가 적용될 때까지 연기되어 계산된다.\n",
    "##이렇게 메모리 연산을 하기 때문에 하둡보다 spark 가 더 빠른것\n",
    "##map()함수의 반환값은 RDD 이다.\n",
    "##즉, 반환값을 실제로 확인해볼라면, collect() 사용하여 출력해야한다.\n",
    "print(squared.collect()) \n",
    "print(type(squared))\n",
    "squared=squared.collect()\n",
    "print(type(squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "myRdd4 = spark.sparkContext\\\n",
    "    .textFile(os.path.join(\"s-master/data\",\"ds_spark_2cols.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35, 2', '40, 27', '12, 38', '15, 31', '21, 1']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#csv에서 배열로\n",
    "##위에서 csv 파일을 읽어서 아래와 같이 구성된 요소를 정수 리스트로 만들어보자\n",
    "myRdd4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['35', ' 2'], ['40', ' 27'], ['12', ' 38'], ['15', ' 31'], ['21', ' 1']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd5 = myRdd4.map(lambda line: line.split(',')) #,로 split 하고 list 생성\n",
    "myRdd5.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 2], [40, 27], [12, 38], [15, 31], [21, 1]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd6 = myRdd5.map(lambda x: [int(i) for i in x])\n",
    "myRdd6.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: x.replace('a', 'AA')\n",
    "lambda x: x.upper()\n",
    "lambda x: x[0].upper() 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd100 = spark.sparkContext.parallelize(range(1,101))\n",
    "myRdd100.reduce(lambda subtotal, x: subtotal+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:  5050\n",
      "min:  1\n",
      "max:  100\n",
      "standard deviation: 28.86607004772212\n",
      "variance:  833.25\n"
     ]
    }
   ],
   "source": [
    "# 단순 통계 기능\n",
    "# 텍스트 데이터와 달리 정량 데이터로부터 sum, min, max, 표준편차 등 서술 통계를 계산할 수 있다. \n",
    "print (\"sum: \", myRdd100.sum())\n",
    "print (\"min: \", myRdd100.min())\n",
    "print (\"max: \", myRdd100.max())\n",
    "print (\"standard deviation:\", myRdd100.stdev())\n",
    "print (\"variance: \", myRdd100.variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many ines having 'Spark':  4\n",
      "Apache Spark is an open source cluster computing framework.\n"
     ]
    }
   ],
   "source": [
    "# filter()\n",
    "myRdd_spark = myRdd2.filter(lambda line: \"Spark\" in line)\n",
    "print(\"How many ines having 'Spark': \", myRdd_spark.count())\n",
    "print(myRdd_spark.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다.\n"
     ]
    }
   ],
   "source": [
    "#한글을 filter 할려면앞에 u 를 붙여준다. u 는 유니코드를 의미\n",
    "myRdd_unicode = myRdd2.filter(lambda line: u\"스파크\" in line)\n",
    "\n",
    "print(myRdd_unicode.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### filter() 사용하여 stopwords 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia Apache Spark open source cluster computing framework. 아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다. Apache Spark Apache Spark Apache Spark Apache Spark 아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크 Originally developed University of California, Berkeley's AMPLab, Spark codebase was later donated to Apache Software Foundation, which has maintained it since. Spark provides interface programming entire clusters with implicit data parallelism and fault-tolerance. "
     ]
    }
   ],
   "source": [
    "stopwords = ['is', 'am', 'are', 'the', 'for','a','an','at']\n",
    "#filter 로 찾고 싶으면 \"word\" in line\n",
    "#filter 로 없애고 싶으면 line not in [\"words\"]\n",
    "#n차원을 1차원으로 :flatMap\n",
    "myRdd_stop = myRdd2.flatMap(lambda x: x.split())\\\n",
    "                    .filter(lambda x: x not in stopwords)\n",
    "\n",
    "for words in myRdd_stop.collect(): #출력해보기\n",
    "    print(words, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foreach() : action 이지만 반환값이 없음\n",
    "spark.sparkContext.parallelize([1,2,3,4,5]).foreach(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize([1,2,3,4,5]).map(lambda x: x+1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): print(x)\n",
    "spark.sparkContext.parallelize([1, 2, 3, 4, 5]).foreach(f)\n",
    "#prompt에선 반환값이 보임: 바로바로 반환값이 보이는 곳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is'], ['a', 'line']]\n"
     ]
    }
   ],
   "source": [
    "myList=[\"this is\",\"a line\"]\n",
    "_rdd=spark.sparkContext.parallelize(myList)\n",
    "wordsRdd=_rdd.map(lambda x:x.split())\n",
    "print (wordsRdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline\n",
    "spark 는 pipeline 형식으로 실행함<br>\n",
    "파이프라인은 transformation, action 함수를 연이어 적용하는 방식을 뜻함<br>\n",
    "하나씩끝내고 결과 받은 후 하는게 아니고 효율적인 처리를 위하여 파이프라인 같이 붙여서 중간결과를 산출하지 않고 연이어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "upper2list = wordsRdd.map(lambda x:[i.upper() for i in x]).collect()\n",
    "print(type(upper2list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "wordsLength = wordsRdd\\\n",
    "    .map(len)\\\n",
    "    .collect()\n",
    "print (wordsLength)\n",
    "#단어의 수를 len() 함수로 세고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일에 쓰기\n",
    "RDD 저장, Spark 에서는 list는 RDD로 만들어 로컬 파일에 쓰게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.parallelize(upper2list).saveAsTextFile(\"data/ds_spark_wiki_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨: Windows-SSD\n",
      " 볼륨 일련 번호: C6A4-826F\n",
      "\n",
      " C:\\Users\\woojung\\Desktop\\AI_WORKS\\02. SelfStudy\\2. DL\\BigData_실습\\data 디렉터리\n",
      "\n",
      "2020-10-19  오전 02:56    <DIR>          .\n",
      "2020-10-19  오전 02:56    <DIR>          ..\n",
      "2020-10-19  오전 02:56    <DIR>          ds_spark_wiki_out\n",
      "               0개 파일                   0 바이트\n",
      "               3개 디렉터리  54,929,940,480 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir data\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  GroupBy  - unpaired RDD\n",
    "키를 선택하여 사용할 수 있음 groupByKey() 와 비교하여 상대적으로 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wi: <pyspark.resultiterable.ResultIterable object at 0x0000012B643DCD08>\n",
      "Ap: <pyspark.resultiterable.ResultIterable object at 0x0000012B643DC388>\n",
      "아파: <pyspark.resultiterable.ResultIterable object at 0x0000012B64468BC8>\n",
      "Or: <pyspark.resultiterable.ResultIterable object at 0x0000012B643E34C8>\n",
      "th: <pyspark.resultiterable.ResultIterable object at 0x0000012B643E3548>\n",
      "wh: <pyspark.resultiterable.ResultIterable object at 0x0000012B643BB148>\n",
      "Sp: <pyspark.resultiterable.ResultIterable object at 0x0000012B643BB888>\n",
      "im: <pyspark.resultiterable.ResultIterable object at 0x0000012B643E3C48>\n"
     ]
    }
   ],
   "source": [
    "myRdd_group=myRdd2.groupBy(lambda x:x[0:2]) #lambda가 key값을 뜻함\n",
    "\n",
    "for (k,v) in myRdd_group.collect(): #key 값을 떼서 가지고 있겠다는 뜻임\n",
    "    print (\"{}: {}\".format(k, v))\n",
    "#key 는 예상 한대로 되었으나 value 는 iterator 로 생성되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResultIterable은 반복문으로 해체하여 결과를 출력하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wi: Wikipedia\n",
      "Ap: Apache Spark is an open source cluster computing framework.\n",
      "Ap: Apache Spark Apache Spark Apache Spark Apache Spark\n",
      "아파: 아파치 스파크는 오픈 소스 클러스터 컴퓨팅 프레임워크이다.\n",
      "아파: 아파치 스파크 아파치 스파크 아파치 스파크 아파치 스파크\n",
      "Or: Originally developed at the University of California, Berkeley's AMPLab,\n",
      "th: the Spark codebase was later donated to the Apache Software Foundation,\n",
      "wh: which has maintained it since.\n",
      "Sp: Spark provides an interface for programming entire clusters with\n",
      "im: implicit data parallelism and fault-tolerance.\n"
     ]
    }
   ],
   "source": [
    "#myRdd_group=myRdd2.flatMap(lambda x:x.split()).groupBy(lambda x:w[0:2])\n",
    "myRdd_group=myRdd2.groupBy(lambda x:x[0:2])\n",
    "\n",
    "for (k,v) in myRdd_group.collect():\n",
    "    for eachValue in v:\n",
    "        print (\"{}: {}\".format(k, eachValue))\n",
    "    #print (\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul', <pyspark.resultiterable.ResultIterable at 0x12b64459848>),\n",
       " ('Busan', <pyspark.resultiterable.ResultIterable at 0x12b643910c8>)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testList=[(\"Seoul\",1),(\"Seoul\",1),(\"Seoul\",1),(\"Busan\",1),(\"Busan\",1),\n",
    "           (\"Seoul\",1),(\"Busan\",1),\n",
    "           (\"Seoul\",1),(\"Seoul\",1),(\"Busan\",1),(\"Busan\",1)]\n",
    "_testRdd = spark.sparkContext.parallelize(_testList)\n",
    "_testRdd.groupBy(lambda x:x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul',\n",
       "  [('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1)]),\n",
       " ('Busan',\n",
       "  [('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1)])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupBy(lambda x: x[0]).mapValues(lambda x: list(x)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair RDD -  paired RDD\n",
    "\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "byKey | 동일한 키에 대해 연산<br>- 단계 1: key-value를 계산한다. 각 key의 빈도를 계산  '(key,1)'<br>- 단계 2: byKey를 적용한다. 동일한 key의 value를 더해준다.\n",
    "byValue | 예, mapValues()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구분 | 설명\n",
    "-----|-----\n",
    "groupByKey() | 같은 key를 grouping, 부분partition에서 **먼저 reduce하지 않고, 전체로 계산**한다.\n",
    "reduceByKey() | 같은 key의 value를 합계, 부분partition에서 **먼저 reduce하고, 전체로 계산**한다. <br>grouping + aggregation. 즉 **reduceByKey = groupByKey().reduce()**\n",
    "combineByKey() | 키별로 합계및 갯수 (key, (sum, count)) **평균 구할때**\n",
    "aggregateByKey() | reduceByKey()와 유사하지만 결과를 다른 형식으로 반환. For example (1,2),(1,4) as input and (1,\"six\") as output\n",
    "mapValues() | PairRDD는 key,value가 있기 마련이다. value에 대해 적용하는 함수이다. 즉 key가 아니라 **value에 적용하는 함수**이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partition\n",
    "_testRdd.getNumPartitions()\n",
    "#데이터를 분할해서 클러스터의 노드에 배분된 논리적인 데이터 조각을 말한다. \n",
    "#현재 partition은 1개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, jsl 2020.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'f'를 사용하면 변수를 그대로 출력할 수 있다.\n",
    "year = 2020\n",
    "name = 'jsl'\n",
    "f\"Hello, {name} {year}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions 0 -> [('Seoul', 1), ('Seoul', 1), ('Seoul', 1), ('Busan', 1), ('Busan', 1), ('Seoul', 1), ('Busan', 1), ('Seoul', 1), ('Seoul', 1), ('Busan', 1), ('Busan', 1)]\n",
      "===========================\n",
      "[[('Seoul', 1), ('Seoul', 1), ('Seoul', 1), ('Busan', 1), ('Busan', 1), ('Seoul', 1), ('Busan', 1), ('Seoul', 1), ('Seoul', 1), ('Busan', 1), ('Busan', 1)]]\n"
     ]
    }
   ],
   "source": [
    "partitions = _testRdd.glom().collect() #partition 세는 방법\n",
    "for num, partition in enumerate(partitions):\n",
    "    print(f'Partitions {num} -> {partition}')\n",
    "print(\"===========================\")\n",
    "# 파티션 하나이니까 하나에 모든 데이터가 들어가 있게 된다\n",
    "print(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Seoul', 1),\n",
       "  ('Seoul', 1),\n",
       "  ('Seoul', 1),\n",
       "  ('Seoul', 1),\n",
       "  ('Seoul', 1),\n",
       "  ('Seoul', 1)],\n",
       " [('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1)]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupBy(lambda x:x[0]).mapValues(list).values().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupByKey().mapValues(list).values().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul', 6), ('Busan', 5)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파티션별로 연산을 하게 된다\n",
    "#동일한 key 에 대해 value 을 합계하게 된다.\n",
    "#reduceByKey 는 partition 별로 작업을 먼저 수행한다.\n",
    "_testRdd.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wikipedia', 1), ('Apache', 6), ('Spark', 7), ('is', 1), ('an', 2)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapValues(sum)을 하면 key 별로 합계를 구할 수 있음 :sum(value)\n",
    "#def f(x): return len(x) len도가능\n",
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .groupByKey()\\\n",
    "    .mapValues(sum)\\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc=myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .reduceByKey(lambda x,y:x+y)\\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어:Wikipedia\t\t빈도:1\n",
      "단어:Apache\t\t빈도:6\n",
      "단어:Spark\t\t빈도:7\n",
      "단어:is\t\t빈도:1\n",
      "단어:an\t\t빈도:2\n",
      "단어:open\t\t빈도:1\n",
      "단어:source\t\t빈도:1\n",
      "단어:cluster\t\t빈도:1\n",
      "단어:computing\t\t빈도:1\n",
      "단어:framework.\t\t빈도:1\n"
     ]
    }
   ],
   "source": [
    "for e in wc:\n",
    "    k = e[0]\n",
    "    v = e[1]\n",
    "    print (f\"단어:{k}\\t\\t빈도:{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Wikipedia': 1,\n",
       "             'Apache': 6,\n",
       "             'Spark': 7,\n",
       "             'is': 1,\n",
       "             'an': 2,\n",
       "             'open': 1,\n",
       "             'source': 1,\n",
       "             'cluster': 1,\n",
       "             'computing': 1,\n",
       "             'framework.': 1,\n",
       "             '아파치': 5,\n",
       "             '스파크는': 1,\n",
       "             '오픈': 1,\n",
       "             '소스': 1,\n",
       "             '클러스터': 1,\n",
       "             '컴퓨팅': 1,\n",
       "             '프레임워크이다.': 1,\n",
       "             '스파크': 4,\n",
       "             'Originally': 1,\n",
       "             'developed': 1,\n",
       "             'at': 1,\n",
       "             'the': 3,\n",
       "             'University': 1,\n",
       "             'of': 1,\n",
       "             'California,': 1,\n",
       "             \"Berkeley's\": 1,\n",
       "             'AMPLab,': 1,\n",
       "             'codebase': 1,\n",
       "             'was': 1,\n",
       "             'later': 1,\n",
       "             'donated': 1,\n",
       "             'to': 1,\n",
       "             'Software': 1,\n",
       "             'Foundation,': 1,\n",
       "             'which': 1,\n",
       "             'has': 1,\n",
       "             'maintained': 1,\n",
       "             'it': 1,\n",
       "             'since.': 1,\n",
       "             'provides': 1,\n",
       "             'interface': 1,\n",
       "             'for': 1,\n",
       "             'programming': 1,\n",
       "             'entire': 1,\n",
       "             'clusters': 1,\n",
       "             'with': 1,\n",
       "             'implicit': 1,\n",
       "             'data': 1,\n",
       "             'parallelism': 1,\n",
       "             'and': 1,\n",
       "             'fault-tolerance.': 1})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .countByKey() #.items() to be added to get a list\n",
    "## dictionary 형태, value -> int 라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombineByKey\n",
    "#### 키별로 합계 및 갯수 (key, (sum, count)) 을 계산\n",
    "combiner = 각 키에 대해 (value, 1) 튜플 만든다\n",
    "<br>\n",
    "merge values = 값을 더해나감 (sum, count) 즉, sum+value, count+1\n",
    "<br>\n",
    "merge combiner = partition 별로 combiner 을 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 생성\n",
    "_testList=[(\"key1\",1),(\"key1\",3),(\"key2\",2),(\"key1\",2),(\"key2\",4),\n",
    "           (\"key1\",5),(\"key2\",6),\n",
    "           (\"key1\",7),(\"key1\",8),(\"key2\",9),(\"key2\",3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#partition 이 1개이면 combiner, mergeValues 만 작동함\n",
    "###RDD 생성\n",
    "_testRdd=spark.sparkContext.parallelize(_testList)\n",
    "\n",
    "### 현재 parition 의 갯수\n",
    "_testRdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', '1*#3#2#5#7#8'), ('key2', '2*#4#6#9#3')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#partition 이 1개이면, 키별로 값을 더해간다.\n",
    "#키가 존재하지 않으면 combiner()를, 존재하면 mergeValues()가 실행\n",
    "\n",
    "#combine, value, 첫번째꺼의 combine 을 더하는 것임\n",
    "#combiner, merge value, merge combiner\n",
    "_testRdd.combineByKey(lambda v : str(v)+\"*\", lambda c, v : c+\"#\"+str(v), lambda c1, c2 : c1+'&'+c2).collect()\n",
    "\n",
    "#partition이 하나임으로 mergecombiner 가 실행되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd = spark.sparkContext.parallelize(_testList, 2)\n",
    "#partitions을 두개로 해준다\n",
    "### 현재 parition 의 갯수\n",
    "_testRdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions 0 -> [('key1', 1), ('key1', 3), ('key2', 2), ('key1', 2), ('key2', 4)]\n",
      "Partitions 1 -> [('key1', 5), ('key2', 6), ('key1', 7), ('key1', 8), ('key2', 9), ('key2', 3)]\n"
     ]
    }
   ],
   "source": [
    "partitions = _testRdd.glom().collect()\n",
    "for num, partition in enumerate(partitions):\n",
    "    print(f'Partitions {num} -> {partition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', '1*#3#2&5*#7#8'), ('key2', '2*#4&6*#9#3')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.combineByKey(lambda v : str(v)+\"*\", lambda c, v : c+\"#\"+str(v), lambda c1, c2 : c1+'&'+c2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', (26, 6)), ('key2', (24, 5))]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.combineByKey(lambda value:(value,1),\n",
    "                     lambda x, value : (x[0]+value, x[1]+1),\n",
    "                     lambda x,y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "_testCbkRdd=_testRdd.combineByKey(lambda value: (value,1),\n",
    "                     lambda x,value: (x[0]+value, x[1]+1),                      \n",
    "                     lambda x,y: (x[0]+y[0], x[1]+y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': 4.333333333333333, 'key2': 4.8}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#평균계산\n",
    "averageByKey = _testCbkRdd.map(lambda x:(x[0],x[1][0]/x[1][1]))\n",
    "averageByKey.collectAsMap()\n",
    "#averageByKey = _testCbkRdd.map(lambda (key, (sum, count)): (key, float(sum)/count))\n",
    "#averageByKey.collectAsMap()\n",
    ".collect()\n",
    "[('key1', 4.333333333333333), ('key2', 4.8)]\n",
    ".collectAsMap()\n",
    "{'key1': 4.333333333333333, 'key2': 4.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 순서\n",
    "('kin' , 86)  | (combiner)  | accum[kim],(86,1)\n",
    "('lim', 87)   | (combiner)  | accum[lim],(87,1)\n",
    "('kim', 75)   | (mergeValue)| accum[kim],75 -> accum[kim],(86+75, 1+1) = (161,2)\n",
    "('kim', 91)   | (mergeValue)| accum[kim],91 -> accum[kim],(161+91, 2+1)\n",
    "\n",
    "##최종\n",
    "(mergeCombiners) | [('lim',(336,4)), ('lee',(99,1)), ('kim', (252,3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = spark.sparkContext.parallelize([('kim',86),('lim',87),('kim',75),\n",
    "                                      ('kim',91),('lim',78),('lim',92),\n",
    "                                      ('lim',79),('lee',99)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kim', (252, 3)), ('lim', (336, 4)), ('lee', (99, 1))]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marksByKey = marks.combineByKey(lambda value: (value,1),\n",
    "                             lambda x,value: (x[0]+value, x[1]+1),\n",
    "                             lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "marksByKey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = spark.sparkContext.parallelize([\n",
    "        ('M',182.),('F',164.),('M',180.),('M',185.),('M',171.),('F',162.)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', (718.0, 4)), ('F', (326.0, 2))]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heightsByKey = heights.combineByKey(lambda value: (value,1),\n",
    "                             lambda x,value: (x[0]+value, x[1]+1),\n",
    "                             lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "heightsByKey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 179.5, 'F': 163.0}\n"
     ]
    }
   ],
   "source": [
    "avgByKey = heightsByKey.map(lambda x: (x[0],x[1][0]/x[1][1]))\n",
    "\n",
    "print (avgByKey.collectAsMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD 와 DataFrame 차이\n",
    "구분 | 설명\n",
    "-----|-----\n",
    "SparkSession.sparkContext.textFile() | **'SparkContext'를 사용하므로 RDD를 생성**한다.\n",
    "SparkSession.read.text() | **DataFrame을 생성**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding : BinaryFiles(이진파일을 읽는 함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popRddBin 은 binaryFiles\n",
    "popRddBin = spark.sparkContext.binaryFiles(os.path.join(\"s-master/data\",\"경기도 의정부시_인구현황_20200904.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#컴퓨터가 이해할 수 있는 binary files kr 로 인코딩하여 우리가 볼수 있게\n",
    "#인코딩을 안하면 print 해도 값이 안보임\n",
    "_my = popRddBin.map(lambda x: x[1].decode('euc-kr'))\n",
    "#_my.take(1) #<class'pyspark.rdd.PipelinedRDD'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비구조적으로 보이기 때문에 \\r\\ 기준으로 split\n",
    "popList = _my.map(lambda x: x.split()).take(3) #type 'list'\n",
    "#popList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#배치 파일 실행할려면\n",
    "\n",
    "%%writefile s-master/src/wooju.py\n",
    "#!/usr/bin/env python3              #실행하는 언어 이름\n",
    "# -*- coding: UTF-8 -*-             # 코드에 한국말이 있으면 유니코드로 바꿔달라는 뜻\n",
    "import os\n",
    "import pyspark\n",
    "\n",
    "def doIt():\n",
    "    print (\"---------RESULT-----------\") #내용 인식하기 위함\n",
    "    popDf = spark\\\n",
    "                .read.option(\"charset\", \"euc-kr\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(os.path.join(\"data\",\"경기도 의정부시_인구현황_20200904.csv\"))\n",
    "    popDf.show(5)\n",
    "    agedDf = spark\\\n",
    "                .read.option(\"charset\", \"euc-kr\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(os.path.join(\"data\",\"제주특별자치도 서귀포시_고령화비율및노령화지수현황_20200623.csv\"))\n",
    "    agedDf.show(5)\n",
    "\n",
    "if __name__ == \"__main__\": #main 함수가 있다는걸 인지해야된다. 프로그램의 시작점\n",
    "    os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
    "    myConf=pyspark.SparkConf()\n",
    "    spark = pyspark.sql.SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"myApp\")\\\n",
    "        .config(conf=myConf)\\\n",
    "        .getOrCreate()\n",
    "    doIt() #doit 함수 호출\n",
    "    spark.stop() # spark 을 stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-submit src/ds3_popCsvRead.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big/data/활용사례/의의[편집]/정치/사회[편집]/2008년/미국/대통령/선거[편집]/2008년/미국/대통령/선거에서/버락/오바마/미국/대통령/후보는/다양한/형태의/유권자/데이터베이스를/확보하여/분석,/활용한/'유권자/맞춤형/선거/전략'을/전개했다./당시/오바마/캠프는/인종,/종교,/나이,/가구형태,/소비수준과/같은/기본/인적/사항으로/유권자를/분류하는/것을/넘어서서/과거/투표/여부,/구독하는/잡지,/마시는/음료/유권자/성향까지/전화나/개별/방문을/소셜/미디어를/통해/유권자/정보를/수집하였다./수집된/데이터는/오바마/캠프/본부로/전송되어/유권자/데이터베이스를/온라인으로/통합관리하는/‘보트빌더(VoteBuilder.com)’시스템의/도움으로/유권자/성향/분석,/미결정/유권자/선별/,/유권자에/대한/예측을/해나갔다./바탕으로‘유권자/지도’를/작성한/뒤/‘유권자/맞춤형/선거/전략’을/전개하는/오바마/캠프는/비용/대비/효과적인/선거를/치를/수/있었다./대한민국/제19대/총선[편집]/중앙선거관리위원회는/대한민국/제19대/총선부터/소셜/네트워크/인터넷/상의/선거/운동을/상시/허용하였다.[15]/이에/소셜/미디어/상에서/선거/관련/데이터는/증폭되었으며,/2010년/대한민국/제5회/지방/선거/2011년/대한민국/재보궐선거에서/소셜/네트워크/서비스의/중요성을/확인한/정당들/또한/SNS/역량/지수를/공천/심사에/반영하는/등[16]/소셜/네트워크/활용에/주목했다./가운데/여론/조사/기관들은/기존/여론조사/방식으로/예측한/2010년/제5회/지방/선거/2011년/재보궐선거의/여론조사/결과와/실제/투표/결과와의/큰/차이를/보완하고자/빅/데이터/기술을/활용한/SNS/여론/분석을/시행했다./그러나/SNS/이용자의/대다수가/수도권/20~30대에/쏠려/있기에[17],/빅/데이터를/이용한/대한민국/제19대/총선에/대한/SNS/분석은/수도권으로/한정되어/일치하는/한계를/드러내기도/하였다./경제/경영[편집]/아마존닷컴의/추천/상품/표시///구글/페이스북의/맞춤형/광고[편집]/아마존닷컴은/모든/고객들의/구매/내역을/데이터베이스에/기록하고,/기록을/분석해/소비자의/소비/취향과/관심사를/파악한다.[18]/빅/데이터의/활용을/통해/아마존은/고객별로/'추천/상품(레코멘데이션)'을/표시한다./고객/한사람/한사람의/취미나/독서/경향을/찾아/일치한다고/생각되는/상품을/메일,/홈/페이지상에서/중점적으로/고객/한사람/한사람에게/자동적으로/제시하는/것이다.[19]/아마존닷컴의/추천/상품/표시와/같은/방식으로/구글/페이스북도/이용자의/검색/조건,/나아가/사진과/동영상/같은/비정형/데이터/사용을/즉각/처리하여/이용자에게/맞춤형/광고를/제공하는/빅데이터의/활용을/증대시키고/있다./문화[편집]/MLB/(메이저/리그/베이스볼)의/머니볼/이론/데이터/야구[편집]/머니볼/이론이란/경기/데이터를/철저하게/분석해/오직/데이터를/기반으로/적재적소에/선수들을/배치해/승률을/높인다는/게임/이론이다.[20]/이는/미국/메이저/리그/베이스볼/오클랜드/어슬레틱스의/구단장/빌리/빈이/리그/전체/25위에/해당하는/낮은/구단/지원금/속에서도/최소비용으로/최대효과를/거둔/상황에서/유래되었다./빌리/빈은/하치해/최하위에/그치던/팀을/4년/연속/포스트시즌에/진출시키고/메이저/리그/최초로/20연승이라는/신기록을/세우도록/탈바꿈/시켰다./미국/월스트리트/저널은/미국/경제에/큰/영향을/끼치는/파워/엘리트/30인에/워렌/버핏,/앨런/그린스펀과/함께/빌리/빈을/선정[21]/하는/머니볼/이론은/경영,/금융/분야에서도/주목받았다./최근/들어서/과학기술/카메라/기술의/발달로/더욱/정교한/데이터의/수집이/가능해졌으며/투구의/궤적/투수의/그립,/타구/방향,/야수의/움직임까지/잡아낼/수/있게/되었다./이처럼/기존의/정형/데이터뿐만/아닌/비정형/데이터의/수집과/분석,/활용을/통해/최근/야구경기에서/빅/데이터의/중요성은/더욱/커지고/있다./선수의/인기만을/쫓는/것이/아니라/팀별/승률이나/선수의/성적을/나타내는/수치와/야구를/관전한다면/그/재미는/배가된다./'출루율'은/타율로/인정되지/않는/볼넷을/포함하여/타자가/성공적으로/베이스를/밟은/횟수의/비율,/'장타율'은/타수마다/밟은/총/베이스를/계산해서/타격력이/얼마나/강한지를/나타내는/비율이다./출루율과/장타율/못지/않게/'타수'는/한두/경기에서/낸/성적이/아닌,/수천/번의/타석에/들어/좋은/성적을/만들어낸/선수를/선별하기/위한/기초/통계자료이다./이처럼/한/선수의/타율에서/팀의/역대/시리즈/전적까지/모든/것을/숫자로/표현할/수/있다고/해서/야구를/'통계의/스포츠'라고/부르기도/한다./야구뿐만/아니라/생활/곳곳에서/활용되는/통계는/복잡한/상황과/설명을/간단한/숫자로/바꿔주는/매우/강력한/도구이다.[22]/'프로파일링'과/'빅데이터'/기법을/활용한/프로그램/MBC/<프로파일링>[편집]/방송에는/19세/소년의/살인/심리를/파헤친/'용인살인사건의/재구성',/강남/3구/초등학교/85곳의/학업성취도평가/성적과/주변/아파트/매매가의/상관관계를/빅데이터(디지털/환경에서/발생한/방대한/규모의/데이터)를/통해/분석한/'강남,/부자일수록/공부를/잘할까'[23]/2014년/FIFA/월드컵/독일/우승과/'빅데이터'[편집]/브라질에서/개최된/2014년/FIFA/월드컵에서/독일은/준결승에서/개최국인/브라질을/7:1로/꺾고,/결승에서/아르헨티나와/연장전까지/가는/접전/끝에/1:0으로/승리를/거두었다./무패행진으로/우승을/차지한/독일/국가대표팀의/우승의/배경에는/'빅데이터'가/있었다./독일/국가대표팀은/SAP와/협업하여/훈련과/실전/경기에/'SAP/매치/인사이트'를/도입했다./SAP/매치/인사이트란/선수들에게/부착된/센서를/통해/운동량,/순간속도,/심박수,/슈팅동작/방대한/비정형/데이터를/수집,/분석한/결과를/감독과/코치의/태블릿PC로/전송하여/그들이/데이터를/기반으로/전술을/짜도록/도와주는/솔루션이다./기존에/감독의/경험이나/주관적/판단으로/결정되는/전략과는/달리,/SAP/매치/인사이트를/통해/이루어지는/분석은/선수들에/대한/분석/뿐만/아니라/상대팀/전력,/강점,/약점/종합적인/분석을/통해/좀/더/과학적인/전략을/수립할/수/있다./정보/수집에/쓰이는/센서/1개가/1분에/만들어내는/데이터는/총/12000여개로/독일/국가대표팀은/선수당/4개(골키퍼는/양/손목을/포함해/6개)의/센서를/부착했고,/90분/경기동안/한/선수당/약/432만개,/팀/전체로/약/4968만개의/데이터를/수집했다고/한다.월드컵8강/獨/전차군단/비밀병기는/'빅데이터'/과학기술/활용[편집]/통계학[편집]/데이터/마이닝이란/기존/데이터베이스/관리도구의/데이터/수집,/저장,/관리,/분석의/역량을/넘어서는/대량의/정형/비정형/데이터/집합/이러한/데이터로부터/가치를/추출하고/결과를/분석하는/기술로,/수집되는/‘빅/데이터’를/보완하고/마케팅,/시청률조사,/경영/등으로부터/체계화돼/분류,/예측,/연관분석/등의/데이터/마이닝을/거쳐/통계학적으로/결과를/도출해/내고/있다.[24][25]/대한민국에서는/2000년부터/정보통신부의/산하단체로/사단법인/한국BI데이터마이닝학회가/설립되어/데이터/마이닝에/관한/학술과/기술을/발전,/보급,/응용하고/있다./‎또한/국내ㆍ외/통계분야에서/서서히/빅/데이터/활용에/대한/관심과/필요성이/커지고/있는/가운데/국가통계/업무를/계획하고/방대한/통계자료를/처리하는/국가기관인/통계청이/빅/데이터를/연구하고/활용방안을/모색하기/위한/'빅/데이터/연구회'를/발족하였다.[26]/하지만/업계에/따르면,/미국과/영국,/일본/선진국들은/이미/빅/데이터를/다각적으로/분석해/조직의/전략방향을/제시하는/데이터과학자/양성에/사활을/걸고/있다./그러나/한국은/정부와/일부/기업이/데이터과학자/양성을/위한/프로그램을/진행/중에/있어/아직/걸음마/단계인/것으로/알려져/있다.[27]/생물정보학[편집]/최근/생물학에서/DNA,/RNA,/단백질/서열/유전자들의/발현과/조절에/대한/데이터의/양이/급격히/증가했고/이에/따라/빅/데이터를/활용한/생명의/이해에/관한/논의가/진행되고/있다./보건의료[편집]/국민건강보험공단은/가입자의/자격·보험료,/진료·투약내용,/건강검진/결과/생활습관/정보/2조1천억건,/92테라바이트의/빅데이터를/보유하고/있고,/한편,/건강보험심사평가원은/진료내역,/투약내용(의약품/안심서비스),/의약품/유통/등의/2조2천억건,/89테라바이트의/빅데이터를/보유하고/있으며,/경제협력개발기구(OECD)는/한국의/건강보험/빅데이터/순위가/2위라고/발표했었다./건보공단과/심평원은/빅데이터를/민간에/널리/알리고/더/많이/개방하고/있다./(연합뉴스/2016.6.14/인터넷뉴스/참조)/빅/데이터를/활용하면/미국/의료부문은/연간/3,300/억/달러(미/정부/의료/예산의/약/8%에/해당하는/규모)의/직간접적인/비용/절감/효과를/보일/것으로/전망된다.[28]/특히/임상분야에서는/의료기관/별/진료방법,/효능,/비용/데이터를/분석하여/보다/효과적인/진료방법을/파악하고/환자/데이터를/온라인/플랫폼화하여/의료협회/데이터/공유로/치료/효과를/제고하며/공중보건/영역에선/전국의/의료/데이터를/연계하여/전염병/발생과/같은/긴박한/순간에/빠른/의사결정을/가능케/할/전망이다.[29]/한편,/의료/분야에서/빅/데이터가/효과를/발휘하기/위해서는/대량의/의료정보/수집이/필수적이기/때문에,/개인정보의/보호와/빅/데이터/활용이라는/가지/가치가/상충하게/되된다./따라서,/의료/분야에서/빅/데이터의/활용과/보급을/위해서는/이러한/문제에/대한/가이드라인/마련이/필요한/상태이다.[30]/기업/경영[편집]/대규모의/다양한/데이터를/활용한/'빅데이터/경영'이/주목받으면서/데이터/품질을/높이고/방대한/데이터의/처리를/돕는/데이터/통합(Data/Integration)의/중요성이/부각되고/있다./데이터/통합(DI)은/데이터의/추출,/변환,/적재를/위한/ETL/솔루션이/핵심인데/ETL/솔루션을/활용하면/일일이/수많은/데이터를/기업/데이터/포맷으로/코딩하지/않아도/되고/데이터/품질을/제고할/수/있기/때문에/DI는/빅데이터/환경에/꼭/필요한/데이터/솔루션으로/평가받고/있는/단계까지/진입되었다./한편/비즈니스/인텔리전스(Business/Intelligence,/BI)보다/진일보한/빅데이터/분석/방법이/비즈니스/애널리틱스(Business/analytics,/BA)인데/고급분석/범주에/있는/BA는/기본적으로/BI를/포함하면서도/미래/예측/기능과/통계분석,/확률/분석/등을/포함해/최적의/데이터/기반/의사결정을/가능케/하는/것으로/평가받고/있기도/하다.[31]/마케팅[편집]/인터넷으로/시작해서/인터넷으로/마감하는/생활,/스마트폰을/이용해/정보를/검색하고/쇼핑도하고/SNS를/이용해서/실시간으로/글을/남기는/등의/다양하게/인터넷을/이용하는/동안/남는/흔적같은/모인/데이터들을/분석하면/개인의/생활/패턴,/소비성향/등을/예측할/수/있고/기업들은/데이터를/통해서/소비자가/원하는/것들을/미리/예측할/수/있다./빅/데이터가/마케팅/자료로/활용되는/사례이다.[31]/기상정보[편집]/한반도/전역의/기상관측정보를/활용해/일기예보와/각종/기상특보/국가/기상서비스를/제공하고/있는/기상청은/정밀한/기상예측을/위한/분석/과정에서/발생하는/데이터/폭증에/대응하고자/빅데이터/저장시스템의/도입을/추진하였다./대다수/스토리지/기업들의/솔루션을/검토한/끝에/한국/IBM의/고성능/대용량/파일공유시스템(General/Parallel/File/System,/이하/GPFS)을/적용한/스토리지/시스템을/선택하였다고/밝혔다./한국IBM이/기상청에/제공한/GPFS/기반의/빅데이터/저장시스템은/IBM/시스템/스토리지/제품군,/시스템/x서버/제품군과/고속/네트워킹/랙스위치(RackSwitch)/등이/통합돼/있는/시스템이다.[31]/보안관리[편집]/보안관리는/빅데이터/환경을/이용해/성장과/기술/발전을/동시에/이루는/분야로/분리한다./클라우드/모바일/환경으로/접어들면서/물리/가상화/IT/시스템의/복잡성이/더욱/높아지고/있어/유무선/네트워크,/프라이빗/퍼블릭/클라우드,/모바일/애플리케이션과/기기관리/IT/시스템/전반에서/대대적인/변화가/예상되고/있어/막대한/양의/보안관리가/중요한/요소로/현실화되고/있다.[32]/구글/번역[편집]/구글에서/제공하는/자동/번역/서비스인/구글/번역은/빅/데이터를/활용한다./지난/40년/컴퓨터/회사/IBM의/자동/번역/프로그램/개발은/컴퓨터가/명사,/형용사,/동사/단어와/어문의/문법적/구조를/인식하여/번역하는/방식으로/이뤄졌다./달리/2006년/구글은/수억/건의/문장과/번역문을/데이터베이스화하여/번역시/유사한/문장과/어구를/기존에/축적된/데이터를/바탕으로/추론해/나가는/통계적/기법을/개발하였다./캐나다/의회의/수백만/건의/문서를/활용하여/영어-불어/자동번역/시스템개발을/시도한/IBM의/자동/번역/프로그램은/실패한/반면/구글은/수억/건의/자료를/활용하여/세계/58개/언어/간의/자동번역/프로그램/개발에/성공하였다./이러한/사례로/미루어/볼/때,/데이터/양의/측면에서의/엄청난/차이가/기업의/자동/번역/프로그램의/번역의/질과/정확도를/결정했으며,/나아가/프로젝트의/성패를/좌우했다고/볼/수/있다.[31]/"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path='./data/'\n",
    "f = open('./s-master/data/ds_bigdata_wiki.txt','r',encoding='UTF-8')\n",
    "#f = open(os.path.join(\"data\",\"ds_bigdata_wiki.txt\"))\n",
    "\n",
    "stopwords =  set(['및','이를', '등','이','이런','그와','또는','두','이와','전','간'])\n",
    "#d = dict()\n",
    "for sent in f.readlines(): \n",
    "    _words = sent.split() # split into words\n",
    "    for word in _words: \n",
    "        if word not in stopwords: #remove stopwords\n",
    "            print(word, end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "f = open('./s-master/data/ds_bigdata_wiki.txt','r',encoding='UTF-8')\n",
    "#f = open(os.path.join(\"data\",\"ds_bigdata_wiki.txt\"))\n",
    "\n",
    "stopwords =  set(['및','이를', '등','이','이런','그와','또는','두','이와','전','간'])\n",
    "d = dict()\n",
    "for sent in f.readlines(): \n",
    "    _words = sent.split() # split into words\n",
    "    for word in _words: \n",
    "        if word not in stopwords: #remove stopwords\n",
    "            if word not in d:\n",
    "                d[word]=1\n",
    "            else:\n",
    "                d[word]=d[word]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Big': 1,\n",
       " 'data': 1,\n",
       " '활용사례': 1,\n",
       " '의의[편집]': 1,\n",
       " '정치': 1,\n",
       " '사회[편집]': 1,\n",
       " '2008년': 2,\n",
       " '미국': 7,\n",
       " '대통령': 3,\n",
       " '선거[편집]': 1,\n",
       " '선거에서': 1,\n",
       " '버락': 1,\n",
       " '오바마': 4,\n",
       " '후보는': 1,\n",
       " '다양한': 2,\n",
       " '형태의': 1,\n",
       " '유권자': 6,\n",
       " '데이터베이스를': 2,\n",
       " '확보하여': 1,\n",
       " '분석,': 3,\n",
       " '활용한': 5,\n",
       " \"'유권자\": 1,\n",
       " '맞춤형': 4,\n",
       " '선거': 6,\n",
       " \"전략'을\": 1,\n",
       " '전개했다.': 1,\n",
       " '당시': 1,\n",
       " '캠프는': 2,\n",
       " '인종,': 1,\n",
       " '종교,': 1,\n",
       " '나이,': 1,\n",
       " '가구형태,': 1,\n",
       " '소비수준과': 1,\n",
       " '같은': 4,\n",
       " '기본': 1,\n",
       " '인적': 1,\n",
       " '사항으로': 1,\n",
       " '유권자를': 1,\n",
       " '분류하는': 1,\n",
       " '것을': 2,\n",
       " '넘어서서': 1,\n",
       " '과거': 1,\n",
       " '투표': 2,\n",
       " '여부,': 1,\n",
       " '구독하는': 1,\n",
       " '잡지,': 1,\n",
       " '마시는': 1,\n",
       " '음료': 1,\n",
       " '성향까지': 1,\n",
       " '전화나': 1,\n",
       " '개별': 1,\n",
       " '방문을': 1,\n",
       " '소셜': 5,\n",
       " '미디어를': 1,\n",
       " '통해': 7,\n",
       " '정보를': 2,\n",
       " '수집하였다.': 1,\n",
       " '수집된': 1,\n",
       " '데이터는': 3,\n",
       " '캠프': 1,\n",
       " '본부로': 1,\n",
       " '전송되어': 1,\n",
       " '온라인으로': 1,\n",
       " '통합관리하는': 1,\n",
       " '‘보트빌더(VoteBuilder.com)’시스템의': 1,\n",
       " '도움으로': 1,\n",
       " '성향': 1,\n",
       " '미결정': 1,\n",
       " '선별': 1,\n",
       " ',': 1,\n",
       " '유권자에': 1,\n",
       " '대한': 6,\n",
       " '예측을': 1,\n",
       " '해나갔다.': 1,\n",
       " '바탕으로‘유권자': 1,\n",
       " '지도’를': 1,\n",
       " '작성한': 1,\n",
       " '뒤': 1,\n",
       " '‘유권자': 1,\n",
       " '전략’을': 1,\n",
       " '전개하는': 1,\n",
       " '비용': 3,\n",
       " '대비': 1,\n",
       " '효과적인': 2,\n",
       " '선거를': 1,\n",
       " '치를': 1,\n",
       " '수': 8,\n",
       " '있었다.': 2,\n",
       " '대한민국': 5,\n",
       " '제19대': 3,\n",
       " '총선[편집]': 1,\n",
       " '중앙선거관리위원회는': 1,\n",
       " '총선부터': 1,\n",
       " '네트워크': 3,\n",
       " '인터넷': 1,\n",
       " '상의': 1,\n",
       " '운동을': 1,\n",
       " '상시': 1,\n",
       " '허용하였다.[15]': 1,\n",
       " '이에': 2,\n",
       " '미디어': 1,\n",
       " '상에서': 1,\n",
       " '관련': 1,\n",
       " '증폭되었으며,': 1,\n",
       " '2010년': 2,\n",
       " '제5회': 2,\n",
       " '지방': 2,\n",
       " '2011년': 2,\n",
       " '재보궐선거에서': 1,\n",
       " '서비스의': 1,\n",
       " '중요성을': 1,\n",
       " '확인한': 1,\n",
       " '정당들': 1,\n",
       " '또한': 1,\n",
       " 'SNS': 4,\n",
       " '역량': 1,\n",
       " '지수를': 1,\n",
       " '공천': 1,\n",
       " '심사에': 1,\n",
       " '반영하는': 1,\n",
       " '등[16]': 1,\n",
       " '활용에': 2,\n",
       " '주목했다.': 1,\n",
       " '가운데': 2,\n",
       " '여론': 2,\n",
       " '조사': 1,\n",
       " '기관들은': 1,\n",
       " '기존': 2,\n",
       " '여론조사': 2,\n",
       " '방식으로': 3,\n",
       " '예측한': 1,\n",
       " '재보궐선거의': 1,\n",
       " '결과와': 1,\n",
       " '실제': 1,\n",
       " '결과와의': 1,\n",
       " '큰': 2,\n",
       " '차이를': 1,\n",
       " '보완하고자': 1,\n",
       " '빅': 14,\n",
       " '데이터': 21,\n",
       " '기술을': 2,\n",
       " '분석을': 2,\n",
       " '시행했다.': 1,\n",
       " '그러나': 2,\n",
       " '이용자의': 2,\n",
       " '대다수가': 1,\n",
       " '수도권': 1,\n",
       " '20~30대에': 1,\n",
       " '쏠려': 1,\n",
       " '있기에[17],': 1,\n",
       " '데이터를': 18,\n",
       " '이용한': 1,\n",
       " '총선에': 1,\n",
       " '분석은': 2,\n",
       " '수도권으로': 1,\n",
       " '한정되어': 1,\n",
       " '일치하는': 1,\n",
       " '한계를': 1,\n",
       " '드러내기도': 1,\n",
       " '하였다.': 1,\n",
       " '경제': 1,\n",
       " '경영[편집]': 2,\n",
       " '아마존닷컴의': 2,\n",
       " '추천': 2,\n",
       " '상품': 2,\n",
       " '표시': 1,\n",
       " '/': 1,\n",
       " '구글': 4,\n",
       " '페이스북의': 1,\n",
       " '광고[편집]': 1,\n",
       " '아마존닷컴은': 1,\n",
       " '모든': 2,\n",
       " '고객들의': 1,\n",
       " '구매': 1,\n",
       " '내역을': 1,\n",
       " '데이터베이스에': 1,\n",
       " '기록하고,': 1,\n",
       " '기록을': 1,\n",
       " '분석해': 3,\n",
       " '소비자의': 1,\n",
       " '소비': 1,\n",
       " '취향과': 1,\n",
       " '관심사를': 1,\n",
       " '파악한다.[18]': 1,\n",
       " '데이터의': 8,\n",
       " '활용을': 3,\n",
       " '아마존은': 1,\n",
       " '고객별로': 1,\n",
       " \"'추천\": 1,\n",
       " \"상품(레코멘데이션)'을\": 1,\n",
       " '표시한다.': 1,\n",
       " '고객': 2,\n",
       " '한사람': 2,\n",
       " '한사람의': 1,\n",
       " '취미나': 1,\n",
       " '독서': 1,\n",
       " '경향을': 1,\n",
       " '찾아': 1,\n",
       " '일치한다고': 1,\n",
       " '생각되는': 1,\n",
       " '상품을': 1,\n",
       " '메일,': 1,\n",
       " '홈': 1,\n",
       " '페이지상에서': 1,\n",
       " '중점적으로': 1,\n",
       " '한사람에게': 1,\n",
       " '자동적으로': 1,\n",
       " '제시하는': 2,\n",
       " '것이다.[19]': 1,\n",
       " '표시와': 1,\n",
       " '페이스북도': 1,\n",
       " '검색': 1,\n",
       " '조건,': 1,\n",
       " '나아가': 2,\n",
       " '사진과': 1,\n",
       " '동영상': 1,\n",
       " '비정형': 4,\n",
       " '사용을': 1,\n",
       " '즉각': 1,\n",
       " '처리하여': 1,\n",
       " '이용자에게': 1,\n",
       " '광고를': 1,\n",
       " '제공하는': 2,\n",
       " '빅데이터의': 1,\n",
       " '증대시키고': 1,\n",
       " '있다.': 9,\n",
       " '문화[편집]': 1,\n",
       " 'MLB': 1,\n",
       " '(메이저': 1,\n",
       " '리그': 4,\n",
       " '베이스볼)의': 1,\n",
       " '머니볼': 3,\n",
       " '이론': 1,\n",
       " '야구[편집]': 1,\n",
       " '이론이란': 1,\n",
       " '경기': 1,\n",
       " '철저하게': 1,\n",
       " '오직': 1,\n",
       " '기반으로': 2,\n",
       " '적재적소에': 1,\n",
       " '선수들을': 1,\n",
       " '배치해': 1,\n",
       " '승률을': 1,\n",
       " '높인다는': 1,\n",
       " '게임': 1,\n",
       " '이론이다.[20]': 1,\n",
       " '이는': 1,\n",
       " '메이저': 2,\n",
       " '베이스볼': 1,\n",
       " '오클랜드': 1,\n",
       " '어슬레틱스의': 1,\n",
       " '구단장': 1,\n",
       " '빌리': 3,\n",
       " '빈이': 1,\n",
       " '전체': 1,\n",
       " '25위에': 1,\n",
       " '해당하는': 2,\n",
       " '낮은': 1,\n",
       " '구단': 1,\n",
       " '지원금': 1,\n",
       " '속에서도': 1,\n",
       " '최소비용으로': 1,\n",
       " '최대효과를': 1,\n",
       " '거둔': 1,\n",
       " '상황에서': 1,\n",
       " '유래되었다.': 1,\n",
       " '빈은': 1,\n",
       " '하치해': 1,\n",
       " '최하위에': 1,\n",
       " '그치던': 1,\n",
       " '팀을': 1,\n",
       " '4년': 1,\n",
       " '연속': 1,\n",
       " '포스트시즌에': 1,\n",
       " '진출시키고': 1,\n",
       " '최초로': 1,\n",
       " '20연승이라는': 1,\n",
       " '신기록을': 1,\n",
       " '세우도록': 1,\n",
       " '탈바꿈': 1,\n",
       " '시켰다.': 1,\n",
       " '월스트리트': 1,\n",
       " '저널은': 1,\n",
       " '경제에': 1,\n",
       " '영향을': 1,\n",
       " '끼치는': 1,\n",
       " '파워': 1,\n",
       " '엘리트': 1,\n",
       " '30인에': 1,\n",
       " '워렌': 1,\n",
       " '버핏,': 1,\n",
       " '앨런': 1,\n",
       " '그린스펀과': 1,\n",
       " '함께': 1,\n",
       " '빈을': 1,\n",
       " '선정[21]': 1,\n",
       " '하는': 2,\n",
       " '이론은': 1,\n",
       " '경영,': 1,\n",
       " '금융': 1,\n",
       " '분야에서도': 1,\n",
       " '주목받았다.': 1,\n",
       " '최근': 3,\n",
       " '들어서': 1,\n",
       " '과학기술': 2,\n",
       " '카메라': 1,\n",
       " '기술의': 1,\n",
       " '발달로': 1,\n",
       " '더욱': 3,\n",
       " '정교한': 1,\n",
       " '수집이': 2,\n",
       " '가능해졌으며': 1,\n",
       " '투구의': 1,\n",
       " '궤적': 1,\n",
       " '투수의': 1,\n",
       " '그립,': 1,\n",
       " '타구': 1,\n",
       " '방향,': 1,\n",
       " '야수의': 1,\n",
       " '움직임까지': 1,\n",
       " '잡아낼': 1,\n",
       " '있게': 1,\n",
       " '되었다.': 1,\n",
       " '이처럼': 2,\n",
       " '기존의': 1,\n",
       " '정형': 2,\n",
       " '데이터뿐만': 1,\n",
       " '아닌': 1,\n",
       " '수집과': 1,\n",
       " '야구경기에서': 1,\n",
       " '중요성은': 1,\n",
       " '커지고': 2,\n",
       " '선수의': 3,\n",
       " '인기만을': 1,\n",
       " '쫓는': 1,\n",
       " '것이': 1,\n",
       " '아니라': 3,\n",
       " '팀별': 1,\n",
       " '승률이나': 1,\n",
       " '성적을': 2,\n",
       " '나타내는': 2,\n",
       " '수치와': 1,\n",
       " '야구를': 2,\n",
       " '관전한다면': 1,\n",
       " '그': 1,\n",
       " '재미는': 1,\n",
       " '배가된다.': 1,\n",
       " \"'출루율'은\": 1,\n",
       " '타율로': 1,\n",
       " '인정되지': 1,\n",
       " '않는': 1,\n",
       " '볼넷을': 1,\n",
       " '포함하여': 1,\n",
       " '타자가': 1,\n",
       " '성공적으로': 1,\n",
       " '베이스를': 2,\n",
       " '밟은': 2,\n",
       " '횟수의': 1,\n",
       " '비율,': 1,\n",
       " \"'장타율'은\": 1,\n",
       " '타수마다': 1,\n",
       " '총': 2,\n",
       " '계산해서': 1,\n",
       " '타격력이': 1,\n",
       " '얼마나': 1,\n",
       " '강한지를': 1,\n",
       " '비율이다.': 1,\n",
       " '출루율과': 1,\n",
       " '장타율': 1,\n",
       " '못지': 1,\n",
       " '않게': 1,\n",
       " \"'타수'는\": 1,\n",
       " '한두': 1,\n",
       " '경기에서': 1,\n",
       " '낸': 1,\n",
       " '성적이': 1,\n",
       " '아닌,': 1,\n",
       " '수천': 1,\n",
       " '번의': 1,\n",
       " '타석에': 1,\n",
       " '들어': 1,\n",
       " '좋은': 1,\n",
       " '만들어낸': 1,\n",
       " '선수를': 1,\n",
       " '선별하기': 1,\n",
       " '위한': 5,\n",
       " '기초': 1,\n",
       " '통계자료이다.': 1,\n",
       " '한': 2,\n",
       " '타율에서': 1,\n",
       " '팀의': 1,\n",
       " '역대': 1,\n",
       " '시리즈': 1,\n",
       " '전적까지': 1,\n",
       " '숫자로': 2,\n",
       " '표현할': 1,\n",
       " '있다고': 1,\n",
       " '해서': 1,\n",
       " \"'통계의\": 1,\n",
       " \"스포츠'라고\": 1,\n",
       " '부르기도': 1,\n",
       " '한다.': 1,\n",
       " '야구뿐만': 1,\n",
       " '생활': 2,\n",
       " '곳곳에서': 1,\n",
       " '활용되는': 2,\n",
       " '통계는': 1,\n",
       " '복잡한': 1,\n",
       " '상황과': 1,\n",
       " '설명을': 1,\n",
       " '간단한': 1,\n",
       " '바꿔주는': 1,\n",
       " '매우': 1,\n",
       " '강력한': 1,\n",
       " '도구이다.[22]': 1,\n",
       " \"'프로파일링'과\": 1,\n",
       " \"'빅데이터'\": 2,\n",
       " '기법을': 2,\n",
       " '프로그램': 3,\n",
       " 'MBC': 1,\n",
       " '<프로파일링>[편집]': 1,\n",
       " '방송에는': 1,\n",
       " '19세': 1,\n",
       " '소년의': 1,\n",
       " '살인': 1,\n",
       " '심리를': 1,\n",
       " '파헤친': 1,\n",
       " \"'용인살인사건의\": 1,\n",
       " \"재구성',\": 1,\n",
       " '강남': 1,\n",
       " '3구': 1,\n",
       " '초등학교': 1,\n",
       " '85곳의': 1,\n",
       " '학업성취도평가': 1,\n",
       " '성적과': 1,\n",
       " '주변': 1,\n",
       " '아파트': 1,\n",
       " '매매가의': 1,\n",
       " '상관관계를': 1,\n",
       " '빅데이터(디지털': 1,\n",
       " '환경에서': 1,\n",
       " '발생한': 1,\n",
       " '방대한': 4,\n",
       " '규모의': 1,\n",
       " '데이터)를': 1,\n",
       " '분석한': 2,\n",
       " \"'강남,\": 1,\n",
       " '부자일수록': 1,\n",
       " '공부를': 1,\n",
       " \"잘할까'[23]\": 1,\n",
       " '2014년': 2,\n",
       " 'FIFA': 2,\n",
       " '월드컵': 1,\n",
       " '독일': 4,\n",
       " '우승과': 1,\n",
       " \"'빅데이터'[편집]\": 1,\n",
       " '브라질에서': 1,\n",
       " '개최된': 1,\n",
       " '월드컵에서': 1,\n",
       " '독일은': 1,\n",
       " '준결승에서': 1,\n",
       " '개최국인': 1,\n",
       " '브라질을': 1,\n",
       " '7:1로': 1,\n",
       " '꺾고,': 1,\n",
       " '결승에서': 1,\n",
       " '아르헨티나와': 1,\n",
       " '연장전까지': 1,\n",
       " '가는': 1,\n",
       " '접전': 1,\n",
       " '끝에': 2,\n",
       " '1:0으로': 1,\n",
       " '승리를': 1,\n",
       " '거두었다.': 1,\n",
       " '무패행진으로': 1,\n",
       " '우승을': 1,\n",
       " '차지한': 1,\n",
       " '국가대표팀의': 1,\n",
       " '우승의': 1,\n",
       " '배경에는': 1,\n",
       " \"'빅데이터'가\": 1,\n",
       " '국가대표팀은': 2,\n",
       " 'SAP와': 1,\n",
       " '협업하여': 1,\n",
       " '훈련과': 1,\n",
       " '실전': 1,\n",
       " '경기에': 1,\n",
       " \"'SAP\": 1,\n",
       " '매치': 3,\n",
       " \"인사이트'를\": 1,\n",
       " '도입했다.': 1,\n",
       " 'SAP': 2,\n",
       " '인사이트란': 1,\n",
       " '선수들에게': 1,\n",
       " '부착된': 1,\n",
       " '센서를': 2,\n",
       " '운동량,': 1,\n",
       " '순간속도,': 1,\n",
       " '심박수,': 1,\n",
       " '슈팅동작': 1,\n",
       " '수집,': 2,\n",
       " '결과를': 3,\n",
       " '감독과': 1,\n",
       " '코치의': 1,\n",
       " '태블릿PC로': 1,\n",
       " '전송하여': 1,\n",
       " '그들이': 1,\n",
       " '전술을': 1,\n",
       " '짜도록': 1,\n",
       " '도와주는': 1,\n",
       " '솔루션이다.': 1,\n",
       " '기존에': 2,\n",
       " '감독의': 1,\n",
       " '경험이나': 1,\n",
       " '주관적': 1,\n",
       " '판단으로': 1,\n",
       " '결정되는': 1,\n",
       " '전략과는': 1,\n",
       " '달리,': 1,\n",
       " '인사이트를': 1,\n",
       " '이루어지는': 1,\n",
       " '선수들에': 1,\n",
       " '분석': 4,\n",
       " '뿐만': 1,\n",
       " '상대팀': 1,\n",
       " '전력,': 1,\n",
       " '강점,': 1,\n",
       " '약점': 1,\n",
       " '종합적인': 1,\n",
       " '좀': 1,\n",
       " '더': 2,\n",
       " '과학적인': 1,\n",
       " '전략을': 1,\n",
       " '수립할': 1,\n",
       " '정보': 2,\n",
       " '수집에': 1,\n",
       " '쓰이는': 1,\n",
       " '센서': 1,\n",
       " '1개가': 1,\n",
       " '1분에': 1,\n",
       " '만들어내는': 1,\n",
       " '12000여개로': 1,\n",
       " '선수당': 2,\n",
       " '4개(골키퍼는': 1,\n",
       " '양': 1,\n",
       " '손목을': 1,\n",
       " '포함해': 2,\n",
       " '6개)의': 1,\n",
       " '부착했고,': 1,\n",
       " '90분': 1,\n",
       " '경기동안': 1,\n",
       " '약': 3,\n",
       " '432만개,': 1,\n",
       " '팀': 1,\n",
       " '전체로': 1,\n",
       " '4968만개의': 1,\n",
       " '수집했다고': 1,\n",
       " '한다.월드컵8강': 1,\n",
       " '獨': 1,\n",
       " '전차군단': 1,\n",
       " '비밀병기는': 1,\n",
       " '활용[편집]': 1,\n",
       " '통계학[편집]': 1,\n",
       " '마이닝이란': 1,\n",
       " '데이터베이스': 1,\n",
       " '관리도구의': 1,\n",
       " '저장,': 1,\n",
       " '관리,': 1,\n",
       " '분석의': 1,\n",
       " '역량을': 1,\n",
       " '넘어서는': 1,\n",
       " '대량의': 2,\n",
       " '집합': 1,\n",
       " '이러한': 3,\n",
       " '데이터로부터': 1,\n",
       " '가치를': 1,\n",
       " '추출하고': 1,\n",
       " '분석하는': 1,\n",
       " '기술로,': 1,\n",
       " '수집되는': 1,\n",
       " '‘빅': 1,\n",
       " '데이터’를': 1,\n",
       " '보완하고': 1,\n",
       " '마케팅,': 1,\n",
       " '시청률조사,': 1,\n",
       " '경영': 1,\n",
       " '등으로부터': 1,\n",
       " '체계화돼': 1,\n",
       " '분류,': 1,\n",
       " '예측,': 1,\n",
       " '연관분석': 1,\n",
       " '등의': 3,\n",
       " '마이닝을': 1,\n",
       " '거쳐': 1,\n",
       " '통계학적으로': 1,\n",
       " '도출해': 1,\n",
       " '내고': 1,\n",
       " '있다.[24][25]': 1,\n",
       " '대한민국에서는': 1,\n",
       " '2000년부터': 1,\n",
       " '정보통신부의': 1,\n",
       " '산하단체로': 1,\n",
       " '사단법인': 1,\n",
       " '한국BI데이터마이닝학회가': 1,\n",
       " '설립되어': 1,\n",
       " '마이닝에': 1,\n",
       " '관한': 2,\n",
       " '학술과': 1,\n",
       " '발전,': 1,\n",
       " '보급,': 1,\n",
       " '응용하고': 1,\n",
       " '\\u200e또한': 1,\n",
       " '국내ㆍ외': 1,\n",
       " '통계분야에서': 1,\n",
       " '서서히': 1,\n",
       " '관심과': 1,\n",
       " '필요성이': 1,\n",
       " '있는': 5,\n",
       " '국가통계': 1,\n",
       " '업무를': 1,\n",
       " '계획하고': 1,\n",
       " '통계자료를': 1,\n",
       " '처리하는': 1,\n",
       " '국가기관인': 1,\n",
       " '통계청이': 1,\n",
       " '연구하고': 1,\n",
       " '활용방안을': 1,\n",
       " '모색하기': 1,\n",
       " \"'빅\": 1,\n",
       " \"연구회'를\": 1,\n",
       " '발족하였다.[26]': 1,\n",
       " '하지만': 1,\n",
       " '업계에': 1,\n",
       " '따르면,': 1,\n",
       " '미국과': 1,\n",
       " '영국,': 1,\n",
       " '일본': 1,\n",
       " '선진국들은': 1,\n",
       " '이미': 1,\n",
       " '다각적으로': 1,\n",
       " '조직의': 1,\n",
       " '전략방향을': 1,\n",
       " '데이터과학자': 2,\n",
       " '양성에': 1,\n",
       " '사활을': 1,\n",
       " '걸고': 1,\n",
       " '한국은': 1,\n",
       " '정부와': 1,\n",
       " '일부': 1,\n",
       " '기업이': 1,\n",
       " '양성을': 1,\n",
       " '프로그램을': 1,\n",
       " '진행': 1,\n",
       " '중에': 1,\n",
       " '있어': 3,\n",
       " '아직': 1,\n",
       " '걸음마': 1,\n",
       " '단계인': 1,\n",
       " '것으로': 3,\n",
       " '알려져': 1,\n",
       " '있다.[27]': 1,\n",
       " '생물정보학[편집]': 1,\n",
       " '생물학에서': 1,\n",
       " 'DNA,': 1,\n",
       " 'RNA,': 1,\n",
       " '단백질': 1,\n",
       " '서열': 1,\n",
       " '유전자들의': 1,\n",
       " '발현과': 1,\n",
       " '조절에': 1,\n",
       " '양이': 1,\n",
       " '급격히': 1,\n",
       " '증가했고': 1,\n",
       " '따라': 1,\n",
       " '생명의': 1,\n",
       " '이해에': 1,\n",
       " '논의가': 1,\n",
       " '진행되고': 1,\n",
       " '보건의료[편집]': 1,\n",
       " '국민건강보험공단은': 1,\n",
       " '가입자의': 1,\n",
       " '자격·보험료,': 1,\n",
       " '진료·투약내용,': 1,\n",
       " '건강검진': 1,\n",
       " '결과': 1,\n",
       " '생활습관': 1,\n",
       " '2조1천억건,': 1,\n",
       " '92테라바이트의': 1,\n",
       " '빅데이터를': 3,\n",
       " '보유하고': 2,\n",
       " '있고,': 1,\n",
       " '한편,': 2,\n",
       " '건강보험심사평가원은': 1,\n",
       " '진료내역,': 1,\n",
       " '투약내용(의약품': 1,\n",
       " '안심서비스),': 1,\n",
       " '의약품': 1,\n",
       " '유통': 1,\n",
       " '2조2천억건,': 1,\n",
       " '89테라바이트의': 1,\n",
       " '있으며,': 1,\n",
       " '경제협력개발기구(OECD)는': 1,\n",
       " '한국의': 1,\n",
       " '건강보험': 1,\n",
       " '빅데이터': 6,\n",
       " '순위가': 1,\n",
       " '2위라고': 1,\n",
       " '발표했었다.': 1,\n",
       " '건보공단과': 1,\n",
       " '심평원은': 1,\n",
       " '민간에': 1,\n",
       " '널리': 1,\n",
       " '알리고': 1,\n",
       " '많이': 1,\n",
       " '개방하고': 1,\n",
       " '(연합뉴스': 1,\n",
       " '2016.6.14': 1,\n",
       " '인터넷뉴스': 1,\n",
       " '참조)': 1,\n",
       " '활용하면': 2,\n",
       " '의료부문은': 1,\n",
       " '연간': 1,\n",
       " '3,300': 1,\n",
       " '억': 1,\n",
       " '달러(미': 1,\n",
       " '정부': 1,\n",
       " '의료': 4,\n",
       " '예산의': 1,\n",
       " '8%에': 1,\n",
       " '규모)의': 1,\n",
       " '직간접적인': 1,\n",
       " '절감': 1,\n",
       " '효과를': 3,\n",
       " '보일': 1,\n",
       " '전망된다.[28]': 1,\n",
       " '특히': 1,\n",
       " '임상분야에서는': 1,\n",
       " '의료기관': 1,\n",
       " '별': 1,\n",
       " '진료방법,': 1,\n",
       " '효능,': 1,\n",
       " '분석하여': 1,\n",
       " '보다': 1,\n",
       " '진료방법을': 1,\n",
       " '파악하고': 1,\n",
       " '환자': 1,\n",
       " '온라인': 1,\n",
       " '플랫폼화하여': 1,\n",
       " '의료협회': 1,\n",
       " '공유로': 1,\n",
       " '치료': 1,\n",
       " '제고하며': 1,\n",
       " '공중보건': 1,\n",
       " '영역에선': 1,\n",
       " '전국의': 1,\n",
       " '연계하여': 1,\n",
       " '전염병': 1,\n",
       " '발생과': 1,\n",
       " '긴박한': 1,\n",
       " '순간에': 1,\n",
       " '빠른': 1,\n",
       " '의사결정을': 2,\n",
       " '가능케': 2,\n",
       " '할': 1,\n",
       " '전망이다.[29]': 1,\n",
       " '분야에서': 2,\n",
       " '데이터가': 2,\n",
       " '발휘하기': 1,\n",
       " '위해서는': 2,\n",
       " '의료정보': 1,\n",
       " '필수적이기': 1,\n",
       " '때문에,': 1,\n",
       " '개인정보의': 1,\n",
       " '보호와': 1,\n",
       " '활용이라는': 1,\n",
       " '가지': 1,\n",
       " '가치가': 1,\n",
       " '상충하게': 1,\n",
       " '되된다.': 1,\n",
       " '따라서,': 1,\n",
       " '활용과': 1,\n",
       " '보급을': 1,\n",
       " '문제에': 1,\n",
       " '가이드라인': 1,\n",
       " '마련이': 1,\n",
       " '필요한': 2,\n",
       " '상태이다.[30]': 1,\n",
       " '기업': 2,\n",
       " '대규모의': 1,\n",
       " \"'빅데이터\": 1,\n",
       " \"경영'이\": 1,\n",
       " '주목받으면서': 1,\n",
       " '품질을': 2,\n",
       " '높이고': 1,\n",
       " '처리를': 1,\n",
       " '돕는': 1,\n",
       " '통합(Data': 1,\n",
       " 'Integration)의': 1,\n",
       " '중요성이': 1,\n",
       " '부각되고': 1,\n",
       " '통합(DI)은': 1,\n",
       " '추출,': 1,\n",
       " '변환,': 1,\n",
       " '적재를': 1,\n",
       " 'ETL': 2,\n",
       " '솔루션이': 1,\n",
       " '핵심인데': 1,\n",
       " '솔루션을': 2,\n",
       " '일일이': 1,\n",
       " '수많은': 1,\n",
       " '포맷으로': 1,\n",
       " '코딩하지': 1,\n",
       " '않아도': 1,\n",
       " '되고': 1,\n",
       " '제고할': 1,\n",
       " '있기': 1,\n",
       " '때문에': 1,\n",
       " 'DI는': 1,\n",
       " '환경에': 1,\n",
       " '꼭': 1,\n",
       " '솔루션으로': 1,\n",
       " '평가받고': 2,\n",
       " '단계까지': 1,\n",
       " '진입되었다.': 1,\n",
       " '한편': 1,\n",
       " '비즈니스': 2,\n",
       " '인텔리전스(Business': 1,\n",
       " 'Intelligence,': 1,\n",
       " 'BI)보다': 1,\n",
       " '진일보한': 1,\n",
       " '방법이': 1,\n",
       " '애널리틱스(Business': 1,\n",
       " 'analytics,': 1,\n",
       " 'BA)인데': 1,\n",
       " '고급분석': 1,\n",
       " '범주에': 1,\n",
       " 'BA는': 1,\n",
       " '기본적으로': 1,\n",
       " 'BI를': 1,\n",
       " '포함하면서도': 1,\n",
       " '미래': 1,\n",
       " '예측': 1,\n",
       " '기능과': 1,\n",
       " '통계분석,': 1,\n",
       " '확률': 1,\n",
       " '등을': 2,\n",
       " '최적의': 1,\n",
       " '기반': 1,\n",
       " '있기도': 1,\n",
       " '하다.[31]': 1,\n",
       " '마케팅[편집]': 1,\n",
       " '인터넷으로': 2,\n",
       " '시작해서': 1,\n",
       " '마감하는': 1,\n",
       " '생활,': 1,\n",
       " '스마트폰을': 1,\n",
       " '이용해': 2,\n",
       " '검색하고': 1,\n",
       " '쇼핑도하고': 1,\n",
       " 'SNS를': 1,\n",
       " '이용해서': 1,\n",
       " '실시간으로': 1,\n",
       " '글을': 1,\n",
       " '남기는': 1,\n",
       " '다양하게': 1,\n",
       " '인터넷을': 1,\n",
       " '이용하는': 1,\n",
       " '동안': 1,\n",
       " '남는': 1,\n",
       " '흔적같은': 1,\n",
       " '모인': 1,\n",
       " '데이터들을': 1,\n",
       " '분석하면': 1,\n",
       " '개인의': 1,\n",
       " '패턴,': 1,\n",
       " '소비성향': 1,\n",
       " '예측할': 2,\n",
       " '있고': 1,\n",
       " '기업들은': 1,\n",
       " '통해서': 1,\n",
       " '소비자가': 1,\n",
       " '원하는': 1,\n",
       " '것들을': 1,\n",
       " '미리': 1,\n",
       " '마케팅': 1,\n",
       " '자료로': 1,\n",
       " '사례이다.[31]': 1,\n",
       " '기상정보[편집]': 1,\n",
       " '한반도': 1,\n",
       " '전역의': 1,\n",
       " '기상관측정보를': 1,\n",
       " '활용해': 1,\n",
       " '일기예보와': 1,\n",
       " '각종': 1,\n",
       " '기상특보': 1,\n",
       " '국가': 1,\n",
       " '기상서비스를': 1,\n",
       " '제공하고': 1,\n",
       " '기상청은': 1,\n",
       " '정밀한': 1,\n",
       " '기상예측을': 1,\n",
       " '과정에서': 1,\n",
       " '발생하는': 1,\n",
       " '폭증에': 1,\n",
       " '대응하고자': 1,\n",
       " '저장시스템의': 1,\n",
       " '도입을': 1,\n",
       " '추진하였다.': 1,\n",
       " '대다수': 1,\n",
       " '스토리지': 3,\n",
       " '기업들의': 1,\n",
       " '검토한': 1,\n",
       " '한국': 1,\n",
       " 'IBM의': 3,\n",
       " '고성능': 1,\n",
       " '대용량': 1,\n",
       " '파일공유시스템(General': 1,\n",
       " 'Parallel': 1,\n",
       " 'File': 1,\n",
       " 'System,': 1,\n",
       " '이하': 1,\n",
       " 'GPFS)을': 1,\n",
       " '적용한': 1,\n",
       " '시스템을': 1,\n",
       " '선택하였다고': 1,\n",
       " '밝혔다.': 1,\n",
       " '한국IBM이': 1,\n",
       " '기상청에': 1,\n",
       " '제공한': 1,\n",
       " 'GPFS': 1,\n",
       " '기반의': 1,\n",
       " '저장시스템은': 1,\n",
       " 'IBM': 1,\n",
       " '시스템': 3,\n",
       " '제품군,': 1,\n",
       " 'x서버': 1,\n",
       " '제품군과': 1,\n",
       " '고속': 1,\n",
       " '네트워킹': 1,\n",
       " '랙스위치(RackSwitch)': 1,\n",
       " '등이': 1,\n",
       " '통합돼': 1,\n",
       " '시스템이다.[31]': 1,\n",
       " '보안관리[편집]': 1,\n",
       " '보안관리는': 1,\n",
       " '환경을': 1,\n",
       " '성장과': 1,\n",
       " '기술': 1,\n",
       " '발전을': 1,\n",
       " '동시에': 1,\n",
       " '이루는': 1,\n",
       " '분야로': 1,\n",
       " '분리한다.': 1,\n",
       " '클라우드': 1,\n",
       " '모바일': 2,\n",
       " '환경으로': 1,\n",
       " '접어들면서': 1,\n",
       " '물리/가상화': 1,\n",
       " 'IT': 2,\n",
       " '시스템의': 1,\n",
       " '복잡성이': 1,\n",
       " '높아지고': 1,\n",
       " '유무선': 1,\n",
       " '네트워크,': 1,\n",
       " '프라이빗/퍼블릭': 1,\n",
       " '클라우드,': 1,\n",
       " '애플리케이션과': 1,\n",
       " '기기관리': 1,\n",
       " '전반에서': 1,\n",
       " '대대적인': 1,\n",
       " '변화가': 1,\n",
       " '예상되고': 1,\n",
       " '막대한': 1,\n",
       " '양의': 2,\n",
       " '보안관리가': 1,\n",
       " '중요한': 1,\n",
       " '요소로': 1,\n",
       " '현실화되고': 1,\n",
       " '있다.[32]': 1,\n",
       " '번역[편집]': 1,\n",
       " '구글에서': 1,\n",
       " '자동': 4,\n",
       " '번역': 4,\n",
       " '서비스인': 1,\n",
       " '번역은': 1,\n",
       " '활용한다.': 1,\n",
       " '지난': 1,\n",
       " '40년': 1,\n",
       " '컴퓨터': 1,\n",
       " '회사': 1,\n",
       " '개발은': 1,\n",
       " '컴퓨터가': 1,\n",
       " '명사,': 1,\n",
       " '형용사,': 1,\n",
       " '동사': 1,\n",
       " '단어와': 1,\n",
       " '어문의': 1,\n",
       " '문법적': 1,\n",
       " '구조를': 1,\n",
       " '인식하여': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어빈도를 Python dictionary d에 저장함.\n",
    "# 이를 정렬하여 다시 dictionary 에 저장해야됨\n",
    "# dictionary 는 key-value 쌍으로 구성되어있다.\n",
    "# 저장된 데이터는 반복문을 사용:\n",
    "#      d.items()으로 하나씩 key, value 을 읽고\n",
    "#      key = lambda x: x[1] 은 값을 키로해서,\n",
    "#      reverse = True :내림차순임\n",
    "dSorted = {k:v for k,v in sorted(d.items(), key=lambda x: x[1], reverse=True)}\n",
    "type(dSorted)\n",
    "\n",
    "#x[0] 기준으로 sorted, x[1] 기준으로 sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터\t21\n",
      "데이터를\t18\n",
      "빅\t14\n",
      "있다.\t9\n",
      "수\t8\n",
      "데이터의\t8\n",
      "미국\t7\n",
      "통해\t7\n",
      "유권자\t6\n",
      "선거\t6\n",
      "대한\t6\n",
      "빅데이터\t6\n"
     ]
    }
   ],
   "source": [
    "d1 = dict()\n",
    "for key, value in dSorted.items(): # items 항목으로 가지고 나옴\n",
    "    if value > 5:\n",
    "        d1[key] = value\n",
    "        print(f\"{key}\\t{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리해야됨.\n",
    "\n",
    "# 지금은 전처리 하지 않고 처리하고 있음. \n",
    "# 교착어인 한국어의 특성을 감안하여 품사처리를 해야할 필요가 있음\n",
    "# 이음 동의도 어떻게 분류할 것인지 감안해야됨\n",
    "# 전처리를 하지않은 문제점을 몇가지 나열 하자면:\n",
    "\n",
    "\n",
    "# '빅데이터' 와 '빅' '데이터' 는 다른 단어로 인식 'big data'도\n",
    "# '대한' 의의미가 모호함\n",
    "# 다수의 한글자 단어가 계산되어있지만, 의미가 모호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRdd3= spark.sparkContext\\\n",
    "            .textFile(os.path.join(\"s-master/data\",\"ds_bigdata_wiki.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big data\n",
      "활용사례 및 의의[편집]\n"
     ]
    }
   ],
   "source": [
    "for i in myRdd3.take(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap vs map\n",
    "## flatMap\n",
    "## flat 해서 map을 하겠다는 뜻임\n",
    "## 리스트 안에 또 리스트가 있는 경우(2차원) 이를 하나의 리스트로 만듦.\n",
    "\n",
    "\n",
    "## map\n",
    "## 리스트 안에 또 리스트가 있는 구조를 보존하고 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Big', 'data']/['활용사례', '및', '의의[편집]']/['정치', '및', '사회[편집]']/"
     ]
    }
   ],
   "source": [
    "wc3 = myRdd3\\\n",
    "        .map(lambda x: x.split())\\\n",
    "        .take(3)\n",
    "for i in wc3:\n",
    "    print(i, end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big/data/활용사례/및/의의[편집]/정치/및/사회[편집]/2008년/미국/"
     ]
    }
   ],
   "source": [
    "wc4 = myRdd3\\\n",
    "        .flatMap(lambda x: x.split())\\\n",
    "        .take(10)\n",
    "for i in wc4:\n",
    "    print(i, end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 제거\n",
    "stopwords =  set(['및','이를', '등','이','이런','그와','또는','두','이와','전','간'])\n",
    "wc3_stop1 = myRdd3\\\n",
    "        .flatMap(lambda x :x.split())\\\n",
    "        .filter(lambda x: x.lower() not in stopwords)\\\n",
    "        .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big',\n",
       " 'data',\n",
       " '활용사례',\n",
       " '의의[편집]',\n",
       " '정치',\n",
       " '사회[편집]',\n",
       " '2008년',\n",
       " '미국',\n",
       " '대통령',\n",
       " '선거[편집]']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc3_stop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big/data/활용사례/의의[편집]/정치/사회[편집]/2008년/미국/대통령/선거[편집]/"
     ]
    }
   ],
   "source": [
    "for i in wc3_stop1:\n",
    "    print(i,end=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Big data', 1)/('활용사례 및 의의[편집]', 1)/('정치 및 사회[편집]', 1)/"
     ]
    }
   ],
   "source": [
    "# 단어빈도\n",
    "# tuple 사용 (단어, 1)\n",
    "# map 을 사용하면, 문장으로 세어짐.\n",
    "wc3 = myRdd3\\\n",
    "        .map (lambda x: (x,1))\\\n",
    "        .take(3)\n",
    "for i in wc3:\n",
    "    print(i, end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big data/1/활용사례 및 의의[편집]/"
     ]
    }
   ],
   "source": [
    "wc3 = myRdd3\\\n",
    "        .flatMap (lambda x: (x,1))\\\n",
    "        .take(3)\n",
    "for i in wc3:\n",
    "    print(i, end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords =  set(['및','이를', '등','이','이런','그와','또는','두','이와','전','간'])\n",
    "# wc3 = myRdd3\\\n",
    "#         .flatMap(lambda x: x.split())\\\n",
    "#         .filter(lambda x: x.lower() not in stopwords)\\ #lower 해주고, 불용어에 없는 단어만 filter\n",
    "#         .map(lambda x: (x,1))\\ #tuple 구조로 만들고\n",
    "#         .reduceByKey(lambda x,y : x+y)\\  #단어 reduce(줄여줌)해주고 단어 세기\n",
    "#         .map(lambda x:(x[1], x[0]))\\ #단어 빈도에 대해서 sorting 할라면 둘의 위치를 바꿔줘야함\n",
    "#         .sortByKey(False)\\ #sort 해줘야함\n",
    "#         .take(15) #15개만\n",
    "\n",
    "wc3=myRdd3\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .filter(lambda x: x.lower() not in stopwords)\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .reduceByKey(lambda x,y:x+y)\\\n",
    "    .map(lambda x:(x[1],x[0]))\\\n",
    "    .sortByKey(False)\\\n",
    "    .take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "21 데이터\n",
      "18 데이터를\n",
      "14 빅\n",
      "9 있다.\n",
      "8 수\n",
      "8 데이터의\n",
      "7 미국\n",
      "7 통해\n",
      "6 유권자\n",
      "6 선거\n",
      "6 대한\n",
      "6 빅데이터\n",
      "5 활용한\n",
      "5 소셜\n",
      "5 대한민국\n"
     ]
    }
   ],
   "source": [
    "#python은 dictionary 이용\n",
    "#spark는 tuple 이용\n",
    "print(type(wc3))\n",
    "for i in wc3:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list() #key\n",
    "v = list() #value\n",
    "for i in wc3:\n",
    "    v.append(i[0])\n",
    "    k.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*- \n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rc('font', family = 'NanumMyeongjo')\n",
    "plt.barh(range(len(v)),v,color = \"black\") #bar 그래프로 그리겠다 ! x는 v의 길이\n",
    "plt.yticks(range(len(v)), k) \n",
    "plt.show()\n",
    "\n",
    "#x값 따로, y값 따로 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "for font in font_manager.fontManager.ttflist:\n",
    "    if 'Myeongjo' in font.name:\n",
    "        print(font.name, font.fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
