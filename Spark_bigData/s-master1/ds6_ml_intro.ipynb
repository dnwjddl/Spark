{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 기계학습\n",
    "\n",
    "* Last updated 20191029TUE0000 20181009TUE0845 20170421 20161125\n",
    "\n",
    "## S.1 학습내용\n",
    "\n",
    "### S.1.1 목표\n",
    "\n",
    "* 기계학습이 무엇인지, 어떤 모델이 있는지 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.1.2 목차\n",
    "\n",
    "* S.2 머신러닝\n",
    "* S.2.1 왜 머신러닝?\n",
    "* S.2.2 supervised vs unsupervised\n",
    "* S.3 기계학습 모델들\n",
    "* S.3.1 regression\n",
    "* S.3.2 군집화\n",
    "* S.3.3 추천\n",
    "* S.3.4 LogisticRegression\n",
    "* S.3.5 svm\n",
    "* S.3.6 Decision Tree\n",
    "* S.3.7 Naive Bayesian\n",
    "* S.4 라이브러리\n",
    "* S.4.1 Spark ml, mllib\n",
    "* S.4.2 관련 라이브러리\n",
    "\n",
    "### S.1.3 문제 \n",
    "\n",
    "* 문제 S-1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.2 머신러닝\n",
    "\n",
    "### S.2.1 왜 머신러닝?\n",
    "\n",
    "기계학습 Machine learning은 말 그대로 컴퓨터가 스스로 학습을 통해 문제를 해결하는 방법을 말한다.\n",
    "컴퓨터가 학습한다면 무엇에서 배우게 되는 것일까?\n",
    "**과거 데이터**에 **숨겨진 패턴**을 찾아내게 된다.\n",
    "회사가 파산할 것인지 예측한다고 하자.\n",
    "재무정보 등 회사가 파산했던 상황의 데이터를 수집하고, 이로 부터 파산에 이르게 된 패턴을 찾아내는 것이다.\n",
    "물론 이때 통계기법이나 알고리즘을 활용한다.\n",
    "\n",
    "즉, 기계학습은 **통계기법이나 알고리즘을 통해 데이터에 숨겨진 패턴을 찾아내거나 분류, 예측**하는 것이다.\n",
    "물론 기계학습이 성공적으로 이루어지면, '사람'을 대신하여 문제를 해결하게 된다.\n",
    "기계학습은:\n",
    "* 사람이 처리하기 어려운 대규모 데이터를 처리할 수 있다.\n",
    "* 사람이 발견하지 못하는 패턴을 발견할 수 있다.\n",
    "* 사람이 저지르기 쉬운 bias를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.2.2 supervised vs unsupervised\n",
    "\n",
    "**supervised learning**은 입력에 대한 결과 값이 있는 경우 사용한다. 즉 입력 데이터에서 수학적으로 알고리즘을 만들어 그 결과 값을 예측한다. \n",
    "에를 들어,\n",
    "\n",
    "* 재무정보, 신용평가 등의 입력으로 기업이 부도날 것인가?\n",
    "* 환자 및 진단 정보로 부터 어떤 병이 있는가?\n",
    "\n",
    "supervised learning은 결과값이 있으므로 오류를 알 수 있고 따라서 정확성을 측정할 수 있다.\n",
    "Naive Bayesian, Decision Tree, 회귀분석, Ensembles 등이 예로 들 수 있다.\n",
    "\n",
    "**unsupervised learning**은 출력 값이 없는 경우, 즉 스스로 숨겨진 패턴을 찾아 특징이 유사한 그룹 cluster로 묶는다.\n",
    "* 정상적, 비정상적인 거래로 구분하거나\n",
    "* 불량고객과 우량고객의 구분하는 경우가 해당된다.\n",
    "\n",
    "Unspervised learning은 KMeans, LDA, SVD, PCA 등을 꼽을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## S.3 기계학습 모델들\n",
    "\n",
    "### S.3.1 regression\n",
    "입력변수를 선형 또는 비선형으로 모델링해서 목표변수를 예측하는 경우에 사용한다. 예를 들어 리뷰, 개봉관 수 등 관련 데이터로 부터 영화의 매출을 예측할 수 있다.\n",
    "\n",
    "### S.3.2 군집화\n",
    "군집의 갯수k를 정하고, 각 데이터 항목을 중심점과 얼마나 멀리 있는지 계산하여, 클러스터에 할당\n",
    "계속 새로운 중심점을 갱신하여 군집의 오류가 최소화할 때까지 계속한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.3.3 추천\n",
    "\n",
    "많은 사람들이 선택하는, 즉 **인기**에 따라 추천하는 경우와 다르다.\n",
    "영화의 경우, **많은 사람들이 본 영화**를 추천하는 것이 아니다.\n",
    "**내가 좋아하는 영화**가 문제인 것이다.\n",
    "취향이 유사한 사람들이 collaborative 좋아하는 제품을 선택 filtering\n",
    "* 홍길동이 좋아하는 영화가 '쾌도 홍길동'이고\n",
    "* 장길산이 좋아하는 영화도 '쾌도 홍길동'이라면 \n",
    "* 홍길동, 장길산은 같은 취향을 가지고 있다고 한다.\n",
    "* 어떤 영화를 선정하면, 그 영화에 대해 유사한 선호를 가질 것이라고 추정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.3.4 LogisticRegression\n",
    "\n",
    "supervised learning의 하나로서\n",
    "예를 들어, 이메일이 spam인지 아닌지 또는 거래가 정상인지 아닌지의 이진분류하는 문제에 적용한다.\n",
    "이 경우 logistic(sigmoid)함수를 사용해서 확률을 강제적으로 0 또는 1로 이진분류한다.\n",
    "Spark는 이진분류만 가능하다.\n",
    "* $log\\frac{p}{1-p} \\in \\{1, 0\\}$\n",
    "    * 0\n",
    "    * 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.3.4 svm\n",
    "\n",
    "* **$L_d$**는 변수가 간단해짐. $\\alpha$를 풀고난 후, 이미 알고 있는 데이터 x,y를 대입해서 해를 구함.\n",
    "\n",
    "* Dual form (Wolfe dual)\n",
    "    * 라그랑주승수로 푼 편미분 결과를 $L_p$에 대입해서 풀면 -> w를 제거하게 됨.\n",
    "    \n",
    "$$\n",
    "    \\begin{aligned}\n",
    "    L_p &= \\frac{1}{2}\\|w\\|^2 - \\sum_{i=1}^{n}{\\alpha_i[y_i(w \\cdot x_i + b)-1]}\\\\\n",
    "    \\text{substitute w = $\\sum \\alpha y x$}\\\\\n",
    "        &= \\frac{1}{2}(\\sum \\alpha yx)^2 - \\sum {\\alpha [y (\\sum \\alpha y x x + b)-1]}\\\\\n",
    "        &= \\frac{1}{2}(\\sum \\alpha yx)^2 - \\sum \\sum \\alpha\\alpha y y x x + b \\sum \\alpha y + \\sum \\alpha\\\\\n",
    "    \\text{substitute $\\sum \\alpha y = 0$}\\\\\n",
    "    L_d&=\\sum_{i=1}^n \\alpha_i\n",
    "        -\\frac12 \\sum_{i=1}^n \\sum_{j=1}^n y_i y_j K(x_i, x_j) \\alpha_i \\alpha_j\\\\\n",
    "    \\text{subject to:}\\\\\n",
    "            \\sum_{i=1}^n y_i \\alpha_i &= 0\\\\\n",
    "            \\alpha_i                  &\\ge 0\\\\\n",
    "            for\\ i=1, 2, \\cdots, n\n",
    "            \\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.3.6 Decision Tree\n",
    "\n",
    "* Gini impurity entropy로 불확실성을 계산한다. 즉 50-50은 가장 불확실하다, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H(S) &= - \\sum_{i=1}^{n}\\ p_i\\ log_2\\ p_i\\\\\n",
    "     &= - p_1 log_2\\ p_1 - p_2 log_2\\ p_2\\ \\ldots\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "* 정보이득을 계산해서, 가장 높은 속성을 선정하여 분기\n",
    "\n",
    "$$\n",
    "IG(A,S) = H(S) - \\sum_{i=1}^m\\ p(i)\\ H(i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.3.7 Naive Bayesian\n",
    "\n",
    "* for c $\\in$ C 모든 클래스에 대해\n",
    "    * $ \\frac{N_c} {N}$ 클래스가 발생할 사전확률을 구한다 ($N_c$ 클래스 발생갯수, N: 전체갯수)\n",
    "    * 가능도 likelihood 갱신\n",
    "    * ML (Maximum likelihood estimation)를 계산하여 결정한다.\n",
    "        * $Y_{ML}=argmax_Y P(X | Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## S.4 라이브러리\n",
    "\n",
    "### S.4.1 Spark ml, mllib\n",
    "\n",
    "* DataFrame API는 ml, RDD API는 mllib를 사용하고 있다.\n",
    "\n",
    "구분 | 설명 | 지원\n",
    "-------|-------|-------\n",
    "mllib | RDD API | 점차 지원을 줄여나감.\n",
    "ml | DataFrame API, Pipelines. | Spark 3.0부터 공식적으로 지원, 이것을 사용하는 것을 추천\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 분류 모델\n",
    "\n",
    "구분 | ML \n",
    "-----|-----\n",
    "ml | LogisticRegression(trainDf)\n",
    "| DecisionTreeClassifier(labelCol=, featuresCol=)\n",
    "| LinearRegression\n",
    "| NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "mllib | SVMWithSGD.train(parsedData, iterations=100)\n",
    "| LogisticRegressionWithLBFGS.train(parsedData)\n",
    "| LinearRegressionWithSGD.train(parsedData)\n",
    "\n",
    "* 훈련과 테스트로 구분한다.\n",
    "\n",
    "```python\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### S.4.2 관련 라이브러리\n",
    "\n",
    "* scikit-learn: Python 기계학습 라이브러리\n",
    "* weka 뉴질랜드 University of Waikato에서 개발된 기계학습 지원 라이브러리. weka는 뉴질랜드 날개없는 새 이름을 본 따 지어졌다.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
